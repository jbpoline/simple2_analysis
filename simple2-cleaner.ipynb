{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as stt\n",
    "import scipy.stats as sst\n",
    "import scipy.linalg as lin\n",
    "import os.path as osp\n",
    "from statsmodels import api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from time import gmtime, strftime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(osp.realpath(osp.curdir))\n",
    "\n",
    "csv_filename = '2019-12-21-simple2_query_output2.csv'\n",
    "csv_filename = '2020-02-11-simple2_query_output.csv'\n",
    "csv_filename = '2020-03-26_simple2_query_output.csv'\n",
    "relative_dir = './data'\n",
    "\n",
    "# relative_path_filename = './data/2019-12-03-simple2_query_output.csv' \n",
    "#relative_path_filename = './data/2019-12-21-simple2_query_output2.csv'\n",
    "relative_path_filename = osp.join(relative_dir, csv_filename)\n",
    "assert osp.exists(relative_path_filename)\n",
    "print(relative_path_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hie = pd.read_csv(relative_path_filename, na_values='nd') #, low_memory=False)\n",
    "original_col_names = list(hie)\n",
    "# column names are unique\n",
    "assert len(original_col_names) == len(set(original_col_names))\n",
    "print(list(hie))\n",
    "col_rename = {'federatedLabel':'structure'}\n",
    "hie.rename(columns=col_rename, inplace=True)\n",
    "print(list(hie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(hie['structure'])\n",
    "[roi for roi in set(hie['softwareLabel']) if ('CC_' in roi and 'Volume_mm3' in roi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mapping file, that contains Freesurfer data elements with link to uberon isAbout\n",
    "\n",
    "# mapping_file = '../segstats_jsonld/segstats_jsonld/mapping_data/freesurfermap.json'\n",
    "mapping_file = '../segstats_jsonld/segstats_jsonld/mapping_data/freesurfer-cdes.json'\n",
    "assert osp.exists(mapping_file)\n",
    "with open(mapping_file, \"r\") as read_file:\n",
    "    roi_map = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes the mapping and spits out a dict with key is uberon \n",
    "# and value is roi definition\n",
    "# eg: {'http://purl.obolibrary.org/obo/UBERON_0001874': 'Putamen'}\n",
    "# will be use to get roi (eg Putamen) across software\n",
    "\n",
    "ube2h = {}\n",
    "label2ube = {}\n",
    "countok=0\n",
    "has_no_isAbout = []\n",
    "has_no_label = []\n",
    "\n",
    "for (k,v) in roi_map.items():\n",
    "    \n",
    "    # the mapping file starts with \"count\" at the level of data elements - need to discard 'count'\n",
    "    if k == 'count': pass\n",
    "    \n",
    "    # v is a dict that contains the CDE - check that we have a isAbout and label    \n",
    "    elif 'isAbout' in v:\n",
    "        countok += 1\n",
    "        if 'label' in v:\n",
    "            if v['label'] != '' and v['label'] not in ('None','none'):\n",
    "                #ube['<' + v['isAbout'] + '>'] = v['label']\n",
    "                #ebu[v['label']] = '<' + v['isAbout'] + '>'\n",
    "                label2ube[v['label']] = v['isAbout']\n",
    "                if v['isAbout'] not in ube2h.keys():\n",
    "                    no_right_or_left = v['label']\n",
    "                    no_right_or_left = no_right_or_left.replace('Right-','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Right ','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Left-','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Left ','')\n",
    "                    no_right_or_left = no_right_or_left.replace(' NVoxels','')\n",
    "                    no_right_or_left = no_right_or_left.replace(' (mm^3)','')\n",
    "                    ube2h[v['isAbout']] = no_right_or_left\n",
    "            else:\n",
    "                has_no_label.append(k)\n",
    "\n",
    "assert has_no_isAbout == []\n",
    "assert countok == len(label2ube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2ube;\n",
    "ube2h\n",
    "h2ube = {v: k for k, v in ube2h.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ube2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_op_merge(df, index='ID', col='softwareLabel', \n",
    "                 values='volume', op='+', newcol='newCol', keepcols=[], verbose=False):\n",
    "    \"\"\"\n",
    "    index: will be the index of the returned df\n",
    "    columns: return df will be \"wide\" based on the values of columns\n",
    "    values: content of the wide df\n",
    "    add_col: name of the column where values of columns are added\n",
    "    keepcols: list of column names to keep\n",
    "    \n",
    "    \"\"\"\n",
    "    # index='ID', columns='softwareLabel', values='volume'\n",
    "\n",
    "    assert set(keepcols).issubset(list(df)) # \n",
    "    \n",
    "    if verbose: print('len(df): ', len(df))    \n",
    "    \n",
    "    tmp_cols = list(set(df[col])) # find values in columns : on what we split\n",
    "    if verbose: print('tmp_cols: ', tmp_cols)\n",
    "        \n",
    "    df.drop_duplicates([index, col, values], inplace=True)\n",
    "    if verbose: print('len(df.dropduplicates): ', len(df))\n",
    "    \n",
    "    newdf = df.pivot(index=index, columns=col, values=values).dropna()\n",
    "    newdf.reset_index() # put the index, 'ID' here, back in a column\n",
    "    if verbose: print('len(newdf: ', len(newdf))\n",
    "\n",
    "    if op == '+':\n",
    "        newdf[newcol] = newdf.loc[:,tmp_cols].sum(axis=1)\n",
    "        newdf.drop(tmp_cols, axis=1, inplace=True)\n",
    "    else:\n",
    "        print(\"not implemented: \", op)\n",
    "        raise\n",
    "        \n",
    "    assert not ('ID' in keepcols)\n",
    "    \n",
    "    # now, create a df with keepcols:\n",
    "    keepdf = df[[index] + keepcols].drop_duplicates()\n",
    "    # print(len(keepdf),len(newdf))\n",
    "    newdf = pd.merge(left=newdf, right=keepdf,\n",
    "                     left_on=index, right_on=index, how='inner').dropna()\n",
    "    if verbose: print('after merge and dropna len(newdf): ', len(newdf))\n",
    "    # print(len(newdf),len(newdf.dropna()))\n",
    "    del keepdf\n",
    "    \n",
    "    return newdf\n",
    "\n",
    "# new_tmp = split_op_merge(tmp, 'ID', 'softwareLabel', 'volume', 'CC_vol', \n",
    "#                        ['study', 'Age', 'Gender']) # , 'Age', 'dx', 'Gender', 'FIQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few dictionary for conveniency\n",
    "\n",
    "tooldic = {'surfer':'https://surfer.nmr.mgh.harvard.edu/', \n",
    "       'fsl':'http://purl.org/nidash/fsl#',\n",
    "       'ants':'http://stnava.github.io/ANTs/'}\n",
    "normalDev = (2, '2', 'Typically Developing Children')\n",
    "patient = (1, '1', 'ADHD-Combined', 'ADHD-Hyperactive/Impulsive', 'ADHD-Inattentive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_conditions(df, tooldic={}, normalDev=(), patient=(), h2ube={}):\n",
    "    \"\"\"\n",
    "    create dic of conditions associated with dataframe df \n",
    "    this will select some **rows** of the dataframe based on the \n",
    "    values of the columns (eg: all normal participants)\n",
    "    \"\"\"\n",
    "    \n",
    "    diccond={}\n",
    "    diccond['left'] = ((df['laterality'] == 'L')|(df['laterality'] == 'Left'))\n",
    "    diccond['right'] = ((df['laterality'] == 'R')|(df['laterality'] == 'Right'))\n",
    "    diccond['latNan'] = (df['laterality'] != 'Right') & (df['laterality'] != 'Left') \\\n",
    "                        & (df['laterality'] != 'R') & (df['laterality'] != 'L')\n",
    "#    diccond['latNan'] = (not diccond['left']) & (not diccond['right'])\n",
    "\n",
    "    #========== age \n",
    "    diccond['age<=20'] = (df['Age'] <= 20)\n",
    "    diccond['age<20'] = (df['Age'] < 20)\n",
    "    diccond['age<12'] = (df['Age'] < 12)\n",
    "    diccond['age>=12'] = (df['Age'] >= 12)\n",
    "    \n",
    "    #========== tool conditions\n",
    "    diccond['fs'] = (df['tool'] == tooldic['surfer'])\n",
    "    diccond['ants'] = (df['tool'] == tooldic['ants'])\n",
    "    diccond['fsl'] = (df['tool'] == tooldic['fsl'])\n",
    "    \n",
    "    #========== IQ conditions\n",
    "    diccond['fiq>0'] = (df['FIQ'] > 0 )\n",
    "    \n",
    "    #========== disease conditions\n",
    "    pop_normDev = False\n",
    "    for pop in normalDev:\n",
    "        # print(np.sum(pop_cond))\n",
    "        pop_normDev = pop_normDev | (df['dx'] == pop)\n",
    "    diccond['normDev'] =  pop_normDev\n",
    "    \n",
    "    pop_patient = False\n",
    "    for pop in patient:\n",
    "        # print(np.sum(pop_cond))\n",
    "        pop_patient = pop_patient | (df['dx'] == pop)\n",
    "    diccond['patient'] =  pop_patient\n",
    "\n",
    "    #=========== ROIs\n",
    "    roi_ub = ''\n",
    "    diccond['bvol'] = (df['softwareLabel'] == 'BVOL (mm^3)')\n",
    "    diccond['brainseg'] = (df['softwareLabel'] == 'Brain Segmentation Volume (mm^3)') \n",
    "    diccond['brainsegwov'] = (df['softwareLabel'] == 'Brain Segmentation Volume Without Ventricles (mm^3)') \n",
    "    diccond['caudate'] = (df['structure'] == h2ube['Caudate'])\n",
    "    diccond['putamen'] = (df['structure'] == h2ube['Putamen'])\n",
    "    diccond['TIV'] = (df['structure'] == h2ube['Estimated Total Intracranial Volume'])\n",
    "#\n",
    "    diccond['wm'] =  (df['structure'] == h2ube['hemisphere cerebral white matter volume'])\n",
    "    diccond['gm'] =  (df['structure'] == h2ube['Total gray matter volume'])\n",
    "    diccond['csf'] =  (df['structure'] == h2ube['CSF'])\n",
    "#\n",
    "    diccond['wmfsl'] =  (df['softwareLabel'] == 'white (mm^3)')\n",
    "    diccond['gmfsl'] =  (df['softwareLabel'] == 'gray (mm^3)')\n",
    "    diccond['csffsl'] =  (df['softwareLabel'] == 'csf (mm^3)')\n",
    "#\n",
    "    diccond['ccant'] =  (df['structure'] == h2ube['CC_Anterior'])\n",
    "    diccond['cccen'] =  (df['structure'] == h2ube['CC_Central'])\n",
    "    diccond['ccpos'] =  (df['structure'] == h2ube['CC_Posterior'])\n",
    "\n",
    "    #=========== CC all subcomponents\n",
    "    CC_rois = [roi for roi in set(df['softwareLabel']) \n",
    "                           if ('CC_' in roi and 'Volume_mm3' in roi)]\n",
    "    ccfs = False\n",
    "    for _roi in CC_rois:\n",
    "        ccfs = ccfs | (df['softwareLabel'] == _roi)\n",
    "    diccond['ccfs'] =  ccfs\n",
    "    \n",
    "    #=========== site\n",
    "    diccond['abide'] = (df['study'].str.contains(\"ABIDE\"))\n",
    "    diccond['adhd200'] = (df['study'].str.contains(\"ADHD\"))\n",
    "    \n",
    "    #=========== Gender\n",
    "    diccond['male'] = (df['Gender']=='Male')\n",
    "    diccond['female'] = (df['Gender']=='Female')\n",
    "\n",
    "    return diccond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "condic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cond(df, cndc, conditions, dropnaset=[],columns={}):\n",
    "    \"\"\"\n",
    "    \n",
    "    input:\n",
    "    -------\n",
    "    \n",
    "    df: dataframe\n",
    "    conditions: list of strings, each str should be a key of the cndc dict\n",
    "    cndc: dict\n",
    "        a dict (eg returned by define_condition) that contains the set of true false for that condition\n",
    "    dropnaset: list\n",
    "        the list of column names in which NaN should be dropped\n",
    "    columns: dict\n",
    "        the dict given to df.rename to rename columms eg: {'oldname':'newname'}\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    dataframe, containing only rows that satisfy the list of conditions 'conditions'\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize array of True \n",
    "    cond = np.full((len(df),), True, dtype=bool)\n",
    "    \n",
    "    for c in conditions:\n",
    "        assert len(cond) == len(cndc[c])\n",
    "        cond = cond & cndc[c]\n",
    "        # print(np.sum(cond))\n",
    "        \n",
    "    # condition = [cond & cndc[c] for c in conditions][0]\n",
    "    # print(len(condition),np.sum(condition))\n",
    "    \n",
    "    # make a copy, drop na if there are some\n",
    "    tmp = df.loc[cond].dropna(subset=dropnaset)\n",
    "    if columns:\n",
    "        tmp.rename(columns=columns, inplace=True)\n",
    "        \n",
    "    if len(tmp) == 0:\n",
    "        print('Warning, len(df)==0' + ' '.join(conditions))\n",
    "        \n",
    "    return tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ['ccfs']\n",
    "condic = define_conditions(hie, tooldic=tooldic, \n",
    "                           normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "tmp = apply_cond(hie, condic, cond)\n",
    "set(tmp['softwareLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmp = split_op_merge(tmp, index='ID', col='softwareLabel', values='volume', newcol='CC_vol', \n",
    "                        keepcols=['study', 'Age', 'Gender'], verbose=True) # , 'Age', 'dx', 'Gender', 'FIQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softw = 'surfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyp1 = ['bvol',softw,'left','age<=20','fiq>0','normDev']\n",
    "# hyp1 = ['fiq>0','abide','caudate', 'putamen']\n",
    "hyp1 = ['female', 'caudate', 'fs', 'fiq>0'] # ,'abide']\n",
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "tmp = apply_cond(hie, condic, hyp1)\n",
    "# print('apply:', len(tmp.dropna(subset=['FIQ', 'volume', 'Gender'])))\n",
    "\n",
    "manual = hie.loc[(hie['Gender']=='Female') & \n",
    "#                 (hie['study'].str.contains(\"ABIDE\")) &\n",
    "                 (hie['structure'] == h2ube['Caudate']) &\n",
    "                 (hie['tool'] == tooldic[softw]) & \n",
    "                 (hie['FIQ'] > 0) ] \n",
    "manual = manual.dropna(subset=['FIQ', 'volume', 'Gender']) #,inplace=True)\n",
    "print('manual: ',len(manual))\n",
    "assert len(tmp.dropna(subset=['FIQ', 'volume', 'Gender'])) == len(manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cond = ['abide'] #,'fiq>0'] # ,'abide']\n",
    "cond = ['adhd200'] #,'fiq>0'] # ,'abide']\n",
    "dropnaset = [] #'FIQ']\n",
    "tmp_df = apply_cond(hie, condic, cond, dropnaset=dropnaset, columns={'volume':'brainvol'})\n",
    "len(set(tmp_df['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = set(hie.structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses\n",
    "\n",
    "PIET-1: Total Brain Volume will positively correlate with IQ (in both sexes across the complete age range).\n",
    "\n",
    "MAC-1: Left striatum volume (caudate + putamen) will positively correlate with IQ in the total (male + female) child (age < 20) group.\n",
    "\n",
    "MAC-2: Left striatum volume (caudate + putamen) will positively correlate with IQ in the male children group.\n",
    "\n",
    "MAC-3: Left striatum volume (caudate + putamen) will not correlate with IQ in the female children group.\n",
    "\n",
    "GANJ-1: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ.\n",
    "\n",
    "GANJ-2: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the young (age < 12) group.\n",
    "\n",
    "GANJ-3: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the adolescent (age > 12) group.\n",
    "\n",
    "GANJ-4:. Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the male (age < 12) group.\n",
    "\n",
    "GANJ-5: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the female (age < 12) group.\n",
    "\n",
    "\n",
    "Kennedy.Dave: Yes, please add then ants (and FSL for the first 4 hypotheses) when you get the chance...\n",
    "\n",
    "#### Can you also do the following extra analyses:  \n",
    "\n",
    "GANJ-0a \n",
    "Corpus Callosum Area vs. Total Brain Volume covary for site\n",
    "\n",
    "GANJ-0b\n",
    "Corpus Callosum Area vs. Age, covary for site\n",
    "\n",
    "MAC hypotheses and use total brain volume as a covariate\n",
    "\n",
    "Correct hypotheses : \n",
    "[hypotheses](https://docs.google.com/spreadsheets/d/1IYbDCvisOjblUkuBs8GN6--gjVSe_qBeR0eGIlTShYU/edit#gid=1945227897)\n",
    "\n",
    "summary variables for all models: mean, sd, min, max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def md2dic(varnames, hyp_name, cond, mdf=None, debug=False):\n",
    "    \"\"\"\n",
    "    Conveniency function for extracting the values from the output table\n",
    "    of statsmodel.formula (import as smf) fit \n",
    "    \n",
    "    \n",
    "    input\n",
    "    -------\n",
    "    varnames: list of string (variables in the model)\n",
    "        varnames[1] is the name of the variable for which we want p, t, nobs, etc\n",
    "    hyp_name: string\n",
    "        name of hyp\n",
    "    cond: list\n",
    "        list of string representing the conditions \n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    dict \n",
    "        key is hyp_name, values is a dict with values for t, p, nobs, ... \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    varname = varnames[1] \n",
    "    table2 = mdf.summary().tables[1].data\n",
    "    cols = table2[0]\n",
    "    #print(cols)\n",
    "    #print(table2)\n",
    "    if debug: \n",
    "        print('varname', varname)\n",
    "        print('hyp_name', hyp_name)\n",
    "        print('table2[0] :',cols)\n",
    "\n",
    "    ther = [r for r in table2 if r[0] == varname]\n",
    "    if debug:\n",
    "        print(table2)\n",
    "        print('the row: ', ther)\n",
    "    ther = ther[0]\n",
    "    \n",
    "    resdic = {}\n",
    "    resdic[hyp_name] = {'P>|t|':ther[cols.index('P>|t|')], \n",
    "             't':ther[cols.index('t')], \n",
    "             'rsquared_adj':\"{:4.3}\".format(mdf.rsquared_adj),\n",
    "             'nobs': \"{:3d}\".format(int(mdf.nobs)),\n",
    "             'conditions': cond,\n",
    "             'variables': varnames\n",
    "            }\n",
    "\n",
    "    return(resdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyp(datadf, hyp_name, hyp, ynxs, resdic={}, correctfor=None, debug=False):\n",
    "    \"\"\"\n",
    "    construct the formula and runs a specific hypothesis on dataframe datadf\n",
    "    the ynxs contain the variables names. If resdic exist, an additional \n",
    "    entry is added \n",
    "\n",
    "    df: pandas dataframe\n",
    "    hyp_name: str\n",
    "        describe the hypothesis\n",
    "    hyp: list\n",
    "        list of string describing the hyp\n",
    "    ynxs: list of str (Ys and Xs)\n",
    "        [0] : explained var Y\n",
    "        [1] : region X1 (for which we want the stats)\n",
    "        [2] : X2, ... additional covariables of the form : ' X2 + X3 ... '\n",
    "    resdic: dict\n",
    "        current dictionary of results to which these resutls are added\n",
    "    correctfor: list of strings\n",
    "        will correct ynxs[1] for the columns which names contain one of the string\n",
    "        \n",
    "    returns\n",
    "    --------\n",
    "    updated result dictionary \n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(ynxs) == 3 # \n",
    "    md = smf.ols(ynxs[0] + \" ~ \" + ynxs[1] + \" + \" + ynxs[2], data=datadf)\n",
    "    mdf = md.fit()\n",
    "    resdicupdate = md2dic(ynxs, hyp_name, hyp, mdf=mdf, debug=debug)\n",
    "    \n",
    "    if correctfor is None:\n",
    "        resdicupdate[hyp_name]['corrcoef'] = np.corrcoef(md.endog, datadf[ynxs[1]])\n",
    "        resdicupdate[hyp_name]['exogcorrectionshape'] = 'NA'\n",
    "        resdicupdate[hyp_name]['exogcorrectionnames'] = []\n",
    "    # get columns in correctfor    # correctfor = ['study']\n",
    "    else:\n",
    "        indx = []\n",
    "        for correct in correctfor:\n",
    "            indx += [md.exog_names.index(col) for col in md.exog_names if correct in col]\n",
    "        indx = list(set(indx)) # avoid possible duplicates\n",
    "        C = md.exog[:,indx] # C for counfound, indx is a list, so should do fancy \n",
    "                            # indexing and pick these cols\n",
    "        endog_corrected = md.endog - (C @ lin.pinv(C) @ md.endog)\n",
    "\n",
    "#        resdicupdate[hyp_name]['corrcoef'] = np.corrcoef(datadf[ynxs[0]], datadf[ynxs[1]])[0,0]\n",
    "        resdicupdate[hyp_name]['corrcoef'] = np.corrcoef(md.endog, datadf[ynxs[1]])[0,1]\n",
    "        resdicupdate[hyp_name]['exogcorrectionshape'] = md.exog[:,indx].shape\n",
    "        resdicupdate[hyp_name]['exogcorrectionnames'] = [md.exog_names[idx] for idx in indx]\n",
    "        # list(itemgetter(*indx)(md.exog_names)) \n",
    "    \n",
    "    \n",
    "    # update resdic with resdicupdate dictionary\n",
    "    resdic.update(resdicupdate)\n",
    "    return resdic\n",
    "    \n",
    "\"\"\"    \n",
    "iq = 'FIQ'\n",
    "tmp = PIET_1_fs_df\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "md = smf.ols(iq + \" ~ \" + volume_of + \" + study \", data=tmp) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "resdic.update(md2dic(volume_of, hyp_name, hyp1, mdf=mdf))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIET-1: Total Brain Volume will positively correlate with IQ (in both sexes across the complete age range).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "print(condic.keys())\n",
    "dropnaset = ['FIQ', 'volume', 'Gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"volume_of = 'brainseg'\n",
    "hyp_name = 'PIET-1_fs'\n",
    "\n",
    "print(list(hie))\n",
    "\n",
    "PIET_1_fs = ['brainseg', 'fiq>0','normDev', 'fs'] # 'bvol','ants','abide']\n",
    "PIET_1_fs_df = apply_cond(hie, condic, PIET_1_fs, dropnaset=dropnaset, \n",
    "                          columns={'volume':volume_of})\n",
    "\n",
    "print('len(PIET_1_fs_df)',len(PIET_1_fs_df))\n",
    "print(list(PIET_1_fs_df))\n",
    "\n",
    "modeldata = smf.ols('FIQ ~ brainseg + study', data=PIET_1_fs_df)\n",
    "modeldatafit = modeldata.fit()\n",
    "\n",
    "print(modeldatafit)\n",
    "# resdic = run_hyp(PIET_1_fs_df, hyp_name, PIET_1_fs, ['FIQ', volume_of, 'study'], \n",
    "#                 resdic={}, debug=False)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(PIET_1_fs_df['FIQ'],PIET_1_fs_df['brainseg'],'.')\n",
    "\"\"\"\n",
    "print(modeldata.endog_names, modeldata.exog_names)\n",
    "\n",
    "# get columns in correctfor\n",
    "print(modeldata.exog.shape)\n",
    "correctfor = ['study']\n",
    "indx = []\n",
    "for correct in correctfor:\n",
    "    indx += [modeldata.exog_names.index(col) for col in modeldata.exog_names if correct in col]\n",
    "\n",
    "print(list(set(indx)))\n",
    "print(modeldata.exog[:,indx].shape)\n",
    "\n",
    "assert np.alltrue(modeldata.exog[:,0]==1)\n",
    "assert np.alltrue(modeldata.endog[:] == PIET_1_fs_df['FIQ'])\n",
    "\n",
    "#modeldatafit.predict()\n",
    "print(modeldata.exog[500:560,indx])\n",
    "print(indx)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'brainseg'\n",
    "hyp_name = 'PIET-1_fs'\n",
    "\n",
    "PIET_1_fs = ['brainseg', 'fiq>0','normDev', 'fs'] # 'bvol','ants','abide']\n",
    "PIET_1_fs_df = apply_cond(hie, condic, PIET_1_fs, dropnaset=dropnaset, \n",
    "                          columns={'volume':volume_of})\n",
    "print('len(PIET_1_fs_df)',len(PIET_1_fs_df))\n",
    "\n",
    "resdic = run_hyp(PIET_1_fs_df, hyp_name, PIET_1_fs, ['FIQ', volume_of, 'study'], \n",
    "                 resdic={}, correctfor = ['study'], debug=False)\n",
    "print(np.corrcoef(PIET_1_fs_df['FIQ'],PIET_1_fs_df['brainseg'])[0,1])\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'fsl_brainvol'\n",
    "hyp_name = 'PIET-1_fsl'\n",
    "\n",
    "PIET_1_fsl = ['fiq>0','normDev', 'fsl']\n",
    "fsl_gm = PIET_1_fsl + ['gmfsl'] #\n",
    "fsl_wm = PIET_1_fsl + ['wmfsl'] #\n",
    "fsl_csf = PIET_1_fsl + ['csffsl'] #\n",
    "\n",
    "fsl_gm_df = apply_cond(hie, condic, fsl_gm, dropnaset=dropnaset, columns={'volume':'fsl_gm'})\n",
    "fsl_wm_df = apply_cond(hie, condic, fsl_wm, dropnaset=dropnaset, columns={'volume':'fsl_wm'})\n",
    "fsl_csf_df = apply_cond(hie, condic, fsl_csf, dropnaset=dropnaset, columns={'volume':'fsl_csf'})\n",
    "\n",
    "fsl_total = pd.merge(left=fsl_gm_df, right=fsl_wm_df[['ID','fsl_wm']], left_on='ID', right_on='ID')\n",
    "fsl_total = pd.merge(left=fsl_total, right=fsl_csf_df[['ID','fsl_csf']], left_on='ID', right_on='ID')\n",
    "fsl_total['fsl_brainvol'] = fsl_total['fsl_csf'] + fsl_total['fsl_wm'] + fsl_total['fsl_gm']\n",
    "print('len(fsl_total)',len(fsl_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdic = run_hyp(fsl_total, hyp_name, PIET_1_fsl, ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### and with ANTS ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'ants_brainvol'\n",
    "hyp_name = 'PIET-1_ants'\n",
    "PIET_1_ants = ['bvol', 'fiq>0', 'normDev', 'ants']\n",
    "PIET_1_ants_df = apply_cond(hie, condic, PIET_1_ants, dropnaset=dropnaset, columns={'volume':'ants_brainvol'})\n",
    "print('len(PIET_1_ants_df)',len(PIET_1_ants_df))\n",
    "\n",
    "resdic = run_hyp(PIET_1_ants_df, hyp_name, PIET_1_ants, ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-1: Left striatum volume (caudate + putamen) will positively correlate with IQ in the total (male + female) child (age < 20) group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df and conditions for left striatum, **all age all gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mac = ['fiq>0', 'normDev', 'left'] # , 'fs' ,'age<20', \n",
    "\n",
    "mac1_caud = cond_mac + ['caudate'] #\n",
    "mac1_put = cond_mac + ['putamen'] #\n",
    "# mac1_tiv = cond_mac + ['fiq>0','normDev','fs','TIV'] #\n",
    "\n",
    "left_caud = apply_cond(hie, condic, mac1_caud, dropnaset=dropnaset, columns={'volume':'caudate'})\n",
    "print(len(left_caud), len(left_caud[(left_caud['tool']==tooldic['surfer'])] )) \n",
    "\n",
    "left_put = apply_cond(hie, condic, mac1_put, dropnaset=dropnaset, columns={'volume':'putamen'})\n",
    "print(len(left_put), len(set(left_put['ID'])))\n",
    "\n",
    "#left_caud.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_stria = pd.merge(left=left_caud, right=left_put[['ID','putamen','tool']], on=['ID','tool'])\n",
    "left_stria['striatum'] = left_stria['caudate'] + left_stria['putamen']\n",
    "print(len(left_stria))\n",
    "\n",
    "left_stria.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_stria_condic = define_conditions(left_stria, tooldic=tooldic, \n",
    "                                      normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "\n",
    "#print((set(left_stria['dx'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-1: Left striatum volume (caudate + putamen) will positively correlate with IQ in the total (male + female) child (age < 20) group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(left_stria))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'striatum_fs'\n",
    "hyp_name = 'MAC-1-fs'\n",
    "mac1_child_fs = ['age<20','fs']\n",
    "mac1_child_df = apply_cond(left_stria, left_stria_condic, mac1_child_fs, columns={'striatum':'striatum_fs'})\n",
    "print(len(mac1_child_df))\n",
    "# print(list(mac1_child_df))\n",
    "resdic = run_hyp(mac1_child_df, hyp_name, cond_mac+mac1_child_fs, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'striatum_fsl'\n",
    "hyp_name = 'MAC-1-fsl'\n",
    "mac1_child_fsl = ['age<20','fsl']\n",
    "mac1_child_df = apply_cond(left_stria, left_stria_condic, mac1_child_fsl, \n",
    "                                                          columns={'striatum':'striatum_fsl'})\n",
    "print(len(mac1_child_df))\n",
    "\n",
    "resdic = run_hyp(mac1_child_df, hyp_name, cond_mac+mac1_child_fsl, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'striatum_ants'\n",
    "hyp_name = 'MAC-1-ants'\n",
    "mac1_child_ants = ['age<20','ants'] #,'abide']\n",
    "mac1_child_df = apply_cond(left_stria, left_stria_condic, mac1_child_ants, \n",
    "                                                          columns={'striatum':'striatum_ants'})\n",
    "print(len(mac1_child_df)) # list(mac1_child_df)\n",
    "assert(len(mac1_child_df) == len(set(mac1_child_df['ID'])))\n",
    "# mac1_child_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdic = run_hyp(mac1_child_df, hyp_name, cond_mac+mac1_child_ants, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "# print(resdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-2: Left striatum volume (caudate + putamen) will positively correlate with IQ in the male children group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'fs'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-2-' + sftw\n",
    "mac2_cond = ['age<20','male', sftw]\n",
    "mac2_df = apply_cond(left_stria, left_stria_condic, mac2_cond)\n",
    "print(len(mac2_df))\n",
    "\n",
    "resdic = run_hyp(mac2_df, hyp_name, cond_mac+mac2_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAC-2 ANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAC-2 FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'fsl'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-2-' + sftw\n",
    "mac2_cond = ['age<20','male', sftw]\n",
    "mac2_df = apply_cond(left_stria, left_stria_condic, mac2_cond)\n",
    "print(len(mac2_df))\n",
    "\n",
    "resdic = run_hyp(mac2_df, hyp_name, cond_mac+mac2_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'ants'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-2-' + sftw\n",
    "mac2_cond = ['age<20','male', sftw]\n",
    "\n",
    "mac2_df = apply_cond(left_stria, left_stria_condic, mac2_cond)\n",
    "print(len(mac2_df))\n",
    "\n",
    "resdic = run_hyp(mac2_df, hyp_name, cond_mac+mac2_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-3: Left striatum volume (caudate + putamen) will not correlate with IQ in the female children group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAC-3 FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'fs'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-3-' + sftw\n",
    "hyp_cond = ['age<20','female', sftw]\n",
    "hyp_df = apply_cond(left_stria, left_stria_condic, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, cond_mac+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAC-3 FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'fsl'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-3-' + sftw\n",
    "hyp_cond = ['age<20','female', sftw]\n",
    "hyp_df = apply_cond(left_stria, left_stria_condic, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, cond_mac+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAC-3 ANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'ants'\n",
    "volume_of = 'striatum'\n",
    "hyp_name = 'MAC-3-' + sftw # + 'abide'\n",
    "hyp_cond = ['age<20','female', sftw] #, 'abide']\n",
    "hyp_df = apply_cond(left_stria, left_stria_condic, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, cond_mac+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute cc and tbv  for GANJ, no age or gender condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "condic.keys()\n",
    "print(list(hie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sftw = 'fs'\n",
    "hyp_Ganj = ['fiq>0','normDev', sftw] #, 'adhd200']# , 'adhd' ,'abide','age<20'\n",
    "\n",
    "hyp_ccant = hyp_Ganj + ['ccant'] #\n",
    "hyp_cccen = hyp_Ganj + ['cccen'] #\n",
    "hyp_ccpos = hyp_Ganj + ['ccpos'] #\n",
    "\n",
    "ccant = apply_cond(hie, condic, hyp_ccant, dropnaset=dropnaset, columns={'volume':'ccant'})\n",
    "cccen = apply_cond(hie, condic, hyp_cccen, dropnaset=dropnaset, columns={'volume':'cccen'})\n",
    "ccpos = apply_cond(hie, condic, hyp_ccpos, dropnaset=dropnaset, columns={'volume':'ccpos'})\n",
    "\n",
    "# Note: Only freesurfer measures CC_* therefore no need to merge on tools as well\n",
    "cc_df = pd.merge(left=ccant, right=cccen[['ID','cccen']], on=['ID']) #,'tools']) # left_on='ID', right_on='ID')\n",
    "cc_df = pd.merge(left=cc_df, right=ccpos[['ID','ccpos']], on=['ID']) #,'tools']) # left_on='ID', right_on='ID')\n",
    "\n",
    "cc_df['cc'] = cc_df['ccant']+cc_df['cccen']+cc_df['ccpos']\n",
    "len(cc_df), len(ccant), len(cccen), len(ccpos)\n",
    "# (654, 654, 654, 654)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftw = 'fs'\n",
    "hyp_Ganj = ['fiq>0','normDev', sftw] #, 'adhd200']# , 'adhd' ,'abide','age<20'\n",
    "cond_ccfs = hyp_Ganj+['ccfs']\n",
    "cond_ccfs_df = apply_cond(hie, condic, cond_ccfs)\n",
    "\n",
    "# print(set(ccfs['softwareLabel']))\n",
    "# \n",
    "cc_df = split_op_merge(cond_ccfs_df, index='ID', col='softwareLabel', values='volume', newcol='cc', \n",
    "                        keepcols=['study', 'Age', 'Gender'], verbose=True) # , 'Age', 'dx', 'Gender', 'FIQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cc_df[cc_df['study'].str.contains(\"ADHD\")]\n",
    "print('664 - len(tmp_df): ', 664 - len(tmp_df))\n",
    "#tmp_df.head(3)\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_ganj = 'GANJ-'\n",
    "\n",
    "hyp_gm = hyp_Ganj + ['gm','latNan'] # + ['adhd200']#\n",
    "gm = apply_cond(hie, condic, hyp_gm, dropnaset=dropnaset, columns={'volume':'gm'})\n",
    "print(gm[['ID','gm','laterality']].head(2),len(gm))\n",
    "\n",
    "hyp_wm = hyp_Ganj + ['wm','latNan'] #\n",
    "wm = apply_cond(hie, condic, hyp_wm, dropnaset=dropnaset, columns={'volume':'wm'})\n",
    "print(wm[['ID','wm','laterality']].head(2),len(wm))\n",
    "\n",
    "hyp_csf = hyp_Ganj + ['csf','latNan'] #\n",
    "csf = apply_cond(hie, condic, hyp_csf, dropnaset=dropnaset, columns={'volume':'csf'})\n",
    "print(csf[['ID','csf','laterality']].head(2),len(csf))\n",
    "\n",
    "tbv = pd.merge(left=gm, right=wm[['ID','wm']], left_on='ID', right_on='ID')\n",
    "tbv = pd.merge(left=tbv, right=csf[['ID','csf']], left_on='ID', right_on='ID')\n",
    "tbv['tbv'] = tbv['wm'] + tbv['gm'] +  tbv['csf']\n",
    "tbv.drop(['wm','gm','csf'], axis=1, inplace=True)\n",
    "\n",
    "print(len(gm), len(wm), len(csf), len(tbv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_tbv = pd.merge(left=tbv, right=cc_df[['ID','cc']], left_on='ID', right_on='ID')\n",
    "condic_cc_tbv = define_conditions(cc_tbv, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cc_tbv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-0a Corpus Callosum Area vs. Total Brain Volume covary for site\n",
    "### GANJ-0b Corpus Callosum Area vs. Age, covary for site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_df =  cc_tbv\n",
    "\n",
    "hyp_name = hyp_ganj + '0a_cc_tbv'\n",
    "#print(len(hyp_df))\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     [ volume_of, 'tbv', 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])\n",
    "\n",
    "hyp_name = hyp_ganj + '0a_tbv_cc'\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     ['tbv',  volume_of, 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])\n",
    "\n",
    "hyp_name = hyp_ganj + '0b_cc_age'\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     [volume_of, 'Age', 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])\n",
    "\n",
    "hyp_name = hyp_ganj + '0b_age_cc'\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     ['Age', volume_of, 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])\n",
    "\n",
    "hyp_name = hyp_ganj + '0c_age_tbv'\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     ['Age', 'tbv', 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])\n",
    "\n",
    "hyp_name = hyp_ganj + '0c_tbv_age'\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj, \n",
    "                     ['tbv', 'Age', 'study'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-1: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_name = hyp_ganj + '1' # + 'abide'\n",
    "hyp_cond = ['age<20'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "hyp_df = apply_cond(cc_tbv, condic_cc_tbv, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study + tbv'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-2: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the young (age < 12) group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_name = hyp_ganj + '2' # + 'abide'\n",
    "hyp_cond = ['age<12'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "hyp_df = apply_cond(cc_tbv, condic_cc_tbv, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study + tbv'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-3: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the adolescent (age > 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_name = hyp_ganj + '3' # + 'abide'\n",
    "hyp_cond = ['age>=12'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "hyp_df = apply_cond(cc_tbv, condic_cc_tbv, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study + tbv'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-4:. Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the male (age < 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_name = hyp_ganj + '4' # + 'abide'\n",
    "hyp_cond = ['age<12','male'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "hyp_df = apply_cond(cc_tbv, condic_cc_tbv, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study + tbv'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-5: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the female (age < 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_of = 'cc'\n",
    "hyp_name = hyp_ganj + '5' \n",
    "hyp_cond = ['age<12','female'] # ,'abide', 'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "hyp_df = apply_cond(cc_tbv, condic_cc_tbv, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "\n",
    "resdic = run_hyp(hyp_df, hyp_name, hyp_Ganj+hyp_cond, \n",
    "                     ['FIQ', volume_of, 'study + tbv'], resdic=resdic, debug=False)\n",
    "print(resdic[hyp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datares = []\n",
    "lhyp = list(resdic.keys())\n",
    "hyp = ['hyp'] + lhyp\n",
    "\n",
    "col_names = list(resdic[lhyp[0]].keys())\n",
    "for idx, col in enumerate(col_names):\n",
    "    datares.append( [col] + [resdic[h][col] for h in lhyp]  )\n",
    "\n",
    "datares = [hyp] + datares\n",
    "resdf = pd.DataFrame.from_records(datares).transpose()\n",
    "resdf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_filename = csv_filename[:-4]+'-'+timestr+'.csv'\n",
    "resdf.to_csv(path_or_buf = output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hyp2 = ['fiq>0','normDev','fs','age<20']\n",
    "hyp2_caud = hyp2 + ['caudate'] # ,'abide']\n",
    "hyp2_put = hyp2 + ['putamen'] # ,'abide']\n",
    "hyp2_tiv = hyp2 + ['TIV'] # ,'abide']\n",
    "tmp_caud = apply_cond(hie, condic, hyp2_caud, dropnaset=dropnaset)\n",
    "caud = split_merge_df(tmp_caud, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+',colrename='caudate')\n",
    "tmp_put = apply_cond(hie, condic, hyp2_put, dropnaset=dropnaset)\n",
    "put = split_merge_df(tmp_put, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+',colrename='putamen')\n",
    "tmp_tiv = apply_cond(hie, condic, hyp2_tiv, dropnaset=dropnaset)\n",
    "print(len(caud), len(put), len(tmp_tiv))\n",
    "\n",
    "stria = pd.merge(left=caud, right=put[['ID','putamen']], left_on='ID', right_on='ID')\n",
    "stria['striatum'] = stria['caudate']+stria['putamen']\n",
    "stria = pd.merge(left=stria, right=tmp_tiv[['ID','volume']], left_on='ID', right_on='ID')\n",
    "stria.rename(columns={'volume':'TIV'},inplace=True)\n",
    "print(list(stria),len(stria))\n",
    "\"\"\";\n",
    "\n",
    "\"\"\"\n",
    "cond_mac = ['fiq>0','normDev', softw,] # ,'age<20']\n",
    "mac_caud = cond_mac + ['caudate'] #\n",
    "mac_put = cond_mac + ['putamen'] #\n",
    "mac_tiv = cond_mac + ['fiq>0','normDev',softw,'TIV'] #\n",
    "\n",
    "left_caud = apply_cond(hie, condic, mac_caud, dropnaset=dropnaset, columns={'volume':'caudate'})\n",
    "left_put = apply_cond(hie, condic, mac_put, dropnaset=dropnaset, columns={'volume':'putamen'})\n",
    "\n",
    "left_stria = pd.merge(left=left_caud, right=left_put[['ID','putamen']], left_on='ID', right_on='ID')\n",
    "left_stria['striatum'] = left_stria['caudate'] + left_stria['putamen']\n",
    "left_stria_condic = define_conditions(left_stria, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "print(len(left_stria))\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "iq = 'FIQ'\n",
    "\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "# md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('striatum') + study \", data=mac1) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "varname = \"Q('striatum')\"\n",
    "hyp_name = 'MAC-1'\n",
    "resdic.update(md2dic(varname, hyp_name, cond_mac+mac1_cond, mdf=mdf))\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#ganj1 = apply_cond(cc_tbv, condic_cc_tbv, ganj1_cond)\n",
    "#print(list(ganj1),len(ganj1))\n",
    "\n",
    "#iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "#md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj1) #  \n",
    "#mdf = md.fit()\n",
    "#print(mdf.summary())\n",
    "\n",
    "#varname, hyp_name = \"Q('cc')\",'GANJ-1'\n",
    "#resdic.update(md2dic(varname, hyp_name, hypGanj+ganj1_cond, mdf=mdf))\n",
    "\"\"\";\n",
    "\n",
    "\"\"\"\n",
    "ganj2_cond = ['age<12'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "ganj2 = apply_cond(cc_tbv, condic_cc_tbv, ganj2_cond)\n",
    "print(list(ganj2),len(ganj2));\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj2) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-2'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj2_cond, mdf=mdf))\n",
    "\"\"\";\n",
    "\n",
    "\"\"\"ganj3_cond = ['age>=12'] #\n",
    "ganj3 = apply_cond(cc_tbv, condic_cc_tbv, ganj3_cond)\n",
    "print(len(ganj3))\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj3) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-3'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj3_cond, mdf=mdf))\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# original_col_names = list(hie)\n",
    "# column names are unique\n",
    "# assert len(original_col_names) == len(set(original_col_names))\n",
    "# print(list(hie))\n",
    "#col_rename = {'federatedLabel':'structure'}\n",
    "#hie.rename(columns=col_rename, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check numbers directly, bypassing convenient functions\n",
    "\n",
    "\"\"\"csv_filename = '2020-02-11-simple2_query_output.csv'\n",
    "relative_dir = './data'\n",
    "relative_path_filename = osp.join(relative_dir, csv_filename)\n",
    "assert osp.exists(relative_path_filename)\n",
    "\n",
    "hie = pd.read_csv(relative_path_filename, na_values='nd') #, low_memory=False)set(hie['study'])\n",
    "\n",
    "htmp = hie[(hie['study'].str.contains(\"ADHD\"))]\n",
    "_adhd = len(set(htmp['ID']))\n",
    "htmp = hie[(hie['study'].str.contains(\"ABIDE\"))]\n",
    "_abide = len(set(htmp['ID']))\n",
    "\n",
    "print(len(set(hie['ID'])))\n",
    "print(_adhd, _abide, _adhd + _abide)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, patient=patient, h2ube=h2ube)\n",
    "condic.keys()\n",
    "print(list(hie))\n",
    "# hyp_cond = ['age<20','female', 'adhd200' ]\n",
    "hyp_cond = ['adhd200' ]\n",
    "hyp_df = apply_cond(hie, condic, hyp_cond)\n",
    "print(len(hyp_df))\n",
    "len(set(hyp_df['ID']))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def split_merge_df(df, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+', colrename=None):\n",
    "    \"\"\"\n",
    "    1. split the df according to 2 (n?) levels of \"spliton\"\n",
    "    2. merge the 2 (n?) dataframes using indx as index\n",
    "    3. keep only \"keep_col\" for the right temporary dataframe\n",
    "    4. perform operation 'op' on the columns \"keep_col\" and name it \n",
    "       'keep_col'+'_'+ levels[0] + op + levels[1]    \n",
    "    \n",
    "    Was developed for adding volumes in right and left structures\n",
    "    \"\"\"\n",
    "    \n",
    "    dflev1 = df[df[spliton]==levels[0]]\n",
    "    dflev2 = df[df[spliton]==levels[1]] \n",
    "\n",
    "    # check that the new dfs have no duplicates in the indx\n",
    "\n",
    "    assert set(dflev1[indx]) == set(dflev2[indx])\n",
    "    assert len(set(dflev1[indx])) == len(dflev1[indx])\n",
    "    \n",
    "    # assert len(set(dflev2[indx])) == len(dflev2[indx])\n",
    "    # suffixes=('_l','_r')\n",
    "    merged_inner = pd.merge(left=dflev1, right=dflev2[[indx,keep_col]], \n",
    "                            left_on=indx, right_on=indx, suffixes=levels, how='inner')\n",
    "#    merged_inner.rename(columns={cols+'_x': cols+'_'+lev1, cols+'_y': cols+'_'+lev2}, inplace=True)\n",
    "\n",
    "    # sum keep_col values in a new column\n",
    "    add_col_name = keep_col + levels[0] + op + levels[1]\n",
    "    if op == '+':\n",
    "        merged_inner[add_col_name] = \\\n",
    "                        merged_inner[keep_col+levels[0]] + merged_inner[keep_col+levels[1]]  \n",
    "    if colrename is not None:\n",
    "        merged_inner.rename(columns={add_col_name:colrename}, inplace=True)\n",
    "    return merged_inner\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    if droplist != []:\n",
    "        for colname in droplist:\n",
    "            colname_y = colname + '_y'\n",
    "            colname_x = colname + '_x'\n",
    "            merged_inner.drop(colname_y, axis=1, inplace=True)\n",
    "            merged_inner.rename(columns={colname_x: colname}, inplace=True)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def pivot_and_add(df, index, columns, values, add_col, keep_cols):\n",
    "    \"\"\"\n",
    "    index: will be the index of the returned df\n",
    "    columns: return df will be \"wide\" based on the values of columns\n",
    "    values: content of the wide df\n",
    "    add_col: name of the column where values of columns are added\n",
    "    keep_cols: list of column names to keep\n",
    "    \n",
    "    \"\"\"\n",
    "    # index='ID', columns='softwareLabel', values='volume'\n",
    "    \n",
    "    add_cols = list(set(df[columns])) # find values in columns\n",
    "    df.drop_duplicates([index, columns, values], inplace=True)\n",
    "    newdf = df.pivot(index=index, columns=columns, values=values).dropna()\n",
    "    newdf.reset_index() # put the index, 'ID' here, back in a column\n",
    "    newdf[add_col] = newdf.loc[:,add_cols].sum(axis=1)\n",
    "    newdf.drop(add_cols, axis=1, inplace=True)\n",
    "    \n",
    "    assert not ('ID' in keep_cols)\n",
    "    \n",
    "    # now, create a df with keep_cols:\n",
    "    keepdf = df[['ID'] + keep_cols].drop_duplicates()\n",
    "    # print(len(keepdf),len(newdf))\n",
    "    newdf = pd.merge(left=newdf, right=keepdf, left_on='ID', right_on='ID').dropna()\n",
    "    # print(len(newdf),len(newdf.dropna()))\n",
    "    del keepdf\n",
    "    \n",
    "    return newdf\n",
    "\"\"\";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
