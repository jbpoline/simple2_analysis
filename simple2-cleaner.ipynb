{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as stt\n",
    "import scipy.stats as sst\n",
    "import os.path as osp\n",
    "from statsmodels import api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jb/code/repronim/simple2/simple2_analysis\n"
     ]
    }
   ],
   "source": [
    "print(osp.realpath(osp.curdir))\n",
    "relative_path_filename = './data/2019-12-03-simple2_query_output.csv'\n",
    "assert osp.exists(relative_path_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['study', 'ID', 'Age', 'dx', 'Gender', 'FIQ', 'PIQ', 'VIQ', 'tool', 'softwareLabel', 'federatedLabel', 'laterality', 'volume']\n",
      "['study', 'ID', 'Age', 'dx', 'Gender', 'FIQ', 'PIQ', 'VIQ', 'tool', 'softwareLabel', 'structure', 'laterality', 'volume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jb/virtualenvs/simple2/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "hie = pd.read_csv(relative_path_filename, na_values='nd') #, low_memory=False)\n",
    "original_col_names = list(hie)\n",
    "# column names are unique\n",
    "assert len(original_col_names) == len(set(original_col_names))\n",
    "print(list(hie))\n",
    "col_rename = {'federatedLabel':'structure'}\n",
    "hie.rename(columns=col_rename, inplace=True)\n",
    "print(list(hie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_file = '../segstats_jsonld/segstats_jsonld/mapping_data/freesurfermap.json'\n",
    "mapping_file = '../segstats_jsonld/segstats_jsonld/mapping_data/freesurfer-cdes.json'\n",
    "assert osp.exists(mapping_file)\n",
    "with open(mapping_file, \"r\") as read_file:\n",
    "    roi_map = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ube2h = {}\n",
    "label2ube = {}\n",
    "countok=0\n",
    "has_no_isAbout = []\n",
    "has_no_label = []\n",
    "\n",
    "for (k,v) in roi_map.items():\n",
    "    \n",
    "    # discard 'count'\n",
    "    if k == 'count': pass\n",
    "    \n",
    "    # v is a dict that contains the CDE - check that we have a isAbout and label    \n",
    "    elif 'isAbout' in v:\n",
    "        countok += 1\n",
    "        if 'label' in v:\n",
    "            if v['label'] != '' and v['label'] not in ('None','none'):\n",
    "                #ube['<' + v['isAbout'] + '>'] = v['label']\n",
    "                #ebu[v['label']] = '<' + v['isAbout'] + '>'\n",
    "                label2ube[v['label']] = v['isAbout']\n",
    "                if v['isAbout'] not in ube2h.keys():\n",
    "                    no_right_or_left = v['label']\n",
    "                    no_right_or_left = no_right_or_left.replace('Right-','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Right ','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Left-','')\n",
    "                    no_right_or_left = no_right_or_left.replace('Left ','')\n",
    "                    no_right_or_left = no_right_or_left.replace(' NVoxels','')\n",
    "                    no_right_or_left = no_right_or_left.replace(' (mm^3)','')\n",
    "                    ube2h[v['isAbout']] = no_right_or_left\n",
    "            else:\n",
    "                has_no_label.append(k)\n",
    "\n",
    "assert has_no_isAbout == []\n",
    "assert countok == len(label2ube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2ube;\n",
    "ube2h\n",
    "h2ube = {v: k for k, v in ube2h.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_merge_df(df, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+', colrename=None):\n",
    "    \"\"\"\n",
    "    1. split the df according to 2 (n?) levels of \"spliton\"\n",
    "    2. merge the 2 (n?) df using indx as index\n",
    "    3. keep only \"keep_col\" for the right temporary df\n",
    "    4. perform op on the columns \"keep_col\" and name it 'keep_col'+'_'+ levels[0] + op + levels[1]    \n",
    "    \n",
    "    example: for adding volumes in right and left structures\n",
    "    \"\"\"\n",
    "    \n",
    "    dflev1 = df[df[spliton]==levels[0]]\n",
    "    dflev2 = df[df[spliton]==levels[1]] \n",
    "\n",
    "    # check that the new dfs have no duplicates in the indx\n",
    "\n",
    "    assert set(dflev1[indx]) == set(dflev2[indx])\n",
    "    assert len(set(dflev1[indx])) == len(dflev1[indx])\n",
    "    \n",
    "    # assert len(set(dflev2[indx])) == len(dflev2[indx])\n",
    "    # suffixes=('_l','_r')\n",
    "    merged_inner = pd.merge(left=dflev1, right=dflev2[[indx,keep_col]], \n",
    "                            left_on=indx, right_on=indx, suffixes=levels, how='inner')\n",
    "#    merged_inner.rename(columns={cols+'_x': cols+'_'+lev1, cols+'_y': cols+'_'+lev2}, inplace=True)\n",
    "\n",
    "    # sum keep_col values in a new column\n",
    "    add_col_name = keep_col + levels[0] + op + levels[1]\n",
    "    if op == '+':\n",
    "        merged_inner[add_col_name] = \\\n",
    "                        merged_inner[keep_col+levels[0]] + merged_inner[keep_col+levels[1]]  \n",
    "    if colrename is not None:\n",
    "        merged_inner.rename(columns={add_col_name:colrename}, inplace=True)\n",
    "    return merged_inner\n",
    "\n",
    "\"\"\"\n",
    "    if droplist != []:\n",
    "        for colname in droplist:\n",
    "            colname_y = colname + '_y'\n",
    "            colname_x = colname + '_x'\n",
    "            merged_inner.drop(colname_y, axis=1, inplace=True)\n",
    "            merged_inner.rename(columns={colname_x: colname}, inplace=True)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooldic = {'surfer':'https://surfer.nmr.mgh.harvard.edu/', \n",
    "       'fsl':'http://purl.org/nidash/fsl#',\n",
    "       'ants':'http://stnava.github.io/ANTs/'}\n",
    "normalDev = (2, '2', 'Typically Developing Children')\n",
    "adhd = (1, '1', 'ADHD-Combined', 'ADHD-Hyperactive/Impulsive', 'ADHD-Inattentive')\n",
    "\n",
    "\n",
    "def define_conditions(df, tooldic={}, normalDev=(), adhd=(), h2ube={}):\n",
    "    \"\"\"\n",
    "    create dic of conditions\n",
    "    \n",
    "    \"\"\"\n",
    "    diccond={}\n",
    "    diccond['left'] = ((df['laterality'] == 'L')|(hie['laterality'] == 'Left'))\n",
    "    diccond['right'] = ((df['laterality'] == 'R')|(hie['laterality'] == 'Right'))\n",
    "    diccond['latNan'] = (df['laterality'] != 'Right') & (df['laterality'] != 'Left')\n",
    "\n",
    "    #========== age \n",
    "    diccond['age<=20'] = (df['Age'] <= 20)\n",
    "    diccond['age<20'] = (df['Age'] < 20)\n",
    "    diccond['age<12'] = (df['Age'] < 12)\n",
    "    diccond['age>=12'] = (df['Age'] >= 12)\n",
    "    \n",
    "    #========== tool conditions\n",
    "    diccond['fs'] = (df['tool'] == tooldic['surfer'])\n",
    "    diccond['ants'] = (df['tool'] == tooldic['ants'])\n",
    "    diccond['fsl'] = (df['tool'] == tooldic['fsl'])\n",
    "    \n",
    "    #========== IQ conditions\n",
    "    diccond['fiq>0'] = (df['FIQ'] > 0 )\n",
    "    \n",
    "    #========== disease conditions\n",
    "    pop_normDev = False\n",
    "    for pop in normalDev:\n",
    "        # print(np.sum(pop_cond))\n",
    "        pop_normDev = pop_normDev | (df['dx'] == pop)\n",
    "    diccond['normDev'] =  pop_normDev\n",
    "    \n",
    "    pop_adhd = False\n",
    "    for pop in adhd:\n",
    "        # print(np.sum(pop_cond))\n",
    "        pop_adhd = pop_adhd | (df['dx'] == pop)\n",
    "    diccond['adhd'] =  pop_adhd\n",
    "\n",
    "    #=========== ROIs\n",
    "    roi_ub = ''\n",
    "    diccond['bvol'] = (df['softwareLabel'] == 'BVOL (mm^3)')\n",
    "    diccond['brainseg'] = (df['softwareLabel'] == 'Brain Segmentation Volume (mm^3)') \n",
    "    diccond['caudate'] = (df['structure'] == h2ube['Caudate'])\n",
    "    diccond['putamen'] = (df['structure'] == h2ube['Putamen'])\n",
    "    diccond['TIV'] = (df['structure'] == h2ube['Estimated Total Intracranial Volume'])\n",
    "#\n",
    "    diccond['wm'] =  (df['structure'] == h2ube['hemisphere cerebral white matter volume'])\n",
    "    diccond['gm'] =  (df['structure'] == h2ube['Total gray matter volume'])\n",
    "    diccond['csf'] =  (df['structure'] == h2ube['CSF'])\n",
    "#\n",
    "    diccond['wmfsl'] =  (df['softwareLabel'] == 'white (mm^3)')\n",
    "    diccond['gmfsl'] =  (df['softwareLabel'] == 'gray (mm^3)')\n",
    "    diccond['csffsl'] =  (df['softwareLabel'] == 'csf (mm^3)')\n",
    "#\n",
    "    diccond['ccant'] =  (df['structure'] == h2ube['CC_Anterior'])\n",
    "    diccond['cccen'] =  (df['structure'] == h2ube['CC_Central'])\n",
    "    diccond['ccpos'] =  (df['structure'] == h2ube['CC_Posterior'])\n",
    "\n",
    "    #=========== site\n",
    "    diccond['abide'] = (df['study'].str.contains(\"ABIDE\"))\n",
    "    diccond['adhd200'] = (df['study'].str.contains(\"ADHD\"))\n",
    "    \n",
    "    #=========== Gender\n",
    "    diccond['male'] = (df['Gender']=='Male')\n",
    "    diccond['female'] = (df['Gender']=='Female')\n",
    "\n",
    "    return diccond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['left', 'right', 'latNan', 'age<=20', 'age<20', 'age<12', 'age>=12', 'fs', 'ants', 'fsl', 'fiq>0', 'normDev', 'adhd', 'bvol', 'brainseg', 'caudate', 'putamen', 'TIV', 'wm', 'gm', 'csf', 'wmfsl', 'gmfsl', 'csffsl', 'ccant', 'cccen', 'ccpos', 'abide', 'adhd200', 'male', 'female'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "condic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cond(df, cndc, conditions, dropnaset=[],columns={}):\n",
    "    \"\"\"\n",
    "    List of conditions\n",
    "    \"\"\"\n",
    "    cond = np.full((len(df),), True, dtype=bool)\n",
    "    \n",
    "    for c in conditions:\n",
    "        cond = cond & cndc[c]\n",
    "        # print(np.sum(cond))\n",
    "        \n",
    "    # condition = [cond & cndc[c] for c in conditions][0]\n",
    "    # print(len(condition),np.sum(condition))\n",
    "    \n",
    "    # make a copy\n",
    "    tmp = df.loc[cond].dropna(subset=dropnaset)\n",
    "    if columns:\n",
    "        tmp.rename(columns=columns, inplace=True)\n",
    "        \n",
    "    if len(tmp) == 0:\n",
    "        print('Warning, len(df)==0')\n",
    "        \n",
    "    return tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "softw = 'ants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual:  342\n"
     ]
    }
   ],
   "source": [
    "# hyp1 = ['bvol',softw,'left','age<=20','fiq>0','normDev']\n",
    "# hyp1 = ['fiq>0','abide','caudate', 'putamen']\n",
    "hyp1 = ['female', 'caudate', softw,'fiq>0'] # ,'abide']\n",
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "tmp = apply_cond(hie, condic, hyp1)\n",
    "# print('apply:', len(tmp.dropna(subset=['FIQ', 'volume', 'Gender'])))\n",
    "\n",
    "manual = hie.loc[(hie['Gender']=='Female') & \n",
    "#                 (hie['study'].str.contains(\"ABIDE\")) &\n",
    "                 (hie['structure'] == h2ube['Caudate']) &\n",
    "                 (hie['tool'] == tooldic[softw]) & \n",
    "                 (hie['FIQ'] > 0) ] \n",
    "manual = manual.dropna(subset=['FIQ', 'volume', 'Gender']) #,inplace=True)\n",
    "print('manual: ',len(manual))\n",
    "assert len(tmp.dropna(subset=['FIQ', 'volume', 'Gender'])) == len(manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cond = ['abide'] #,'fiq>0'] # ,'abide']\n",
    "cond = ['adhd200'] #,'fiq>0'] # ,'abide']\n",
    "dropnaset = [] #'FIQ']\n",
    "tmp_df = apply_cond(hie, condic, cond, dropnaset=dropnaset, columns={'volume':'brainvol'})\n",
    "len(set(tmp_df['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = set(hie.structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses\n",
    "\n",
    "PIET-1: Total Brain Volume will positively correlate with IQ (in both sexes across the complete age range).\n",
    "\n",
    "MAC-1: Left striatum volume (caudate + putamen) will positively correlate with IQ in the total (male + female) child (age < 20) group.\n",
    "\n",
    "MAC-2: Left striatum volume (caudate + putamen) will positively correlate with IQ in the male children group.\n",
    "\n",
    "MAC-3: Left striatum volume (caudate + putamen) will not correlate with IQ in the female children group.\n",
    "\n",
    "GANJ-1: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ.\n",
    "\n",
    "GANJ-2: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the young (age < 12) group.\n",
    "\n",
    "GANJ-3: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the adolescent (age > 12) group.\n",
    "\n",
    "GANJ-4:. Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the male (age < 12) group.\n",
    "\n",
    "GANJ-5: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the female (age < 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdic = {}\n",
    "\n",
    "\n",
    "def md2dic(varname, hyp_name, cond, mdf=None):\n",
    "    table2 = mdf.summary().tables[1].data\n",
    "    cols = table2[0]\n",
    "    #print(cols)\n",
    "    #print(table2)\n",
    "    ther = [r for r in table2 if r[0] == varname][0]\n",
    "    resdic = {}\n",
    "    resdic[hyp_name] = {'P>|t|':ther[cols.index('P>|t|')], \n",
    "             't':ther[cols.index('t')], \n",
    "             'rsquared_adj':\"{:4.3}\".format(md.fit().rsquared_adj),\n",
    "             'nobs': \"{:3d}\".format(int(md.nobs)),\n",
    "             'conditions': cond\n",
    "            }\n",
    "\n",
    "    return(resdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIET-1: Total Brain Volume will positively correlate with IQ (in both sexes across the complete age range).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['left', 'right', 'latNan', 'age<=20', 'age<20', 'age<12', 'age>=12', 'fs', 'ants', 'fsl', 'fiq>0', 'normDev', 'adhd', 'bvol', 'brainseg', 'caudate', 'putamen', 'TIV', 'wm', 'gm', 'csf', 'wmfsl', 'gmfsl', 'csffsl', 'ccant', 'cccen', 'ccpos', 'abide', 'adhd200', 'male', 'female'])\n"
     ]
    }
   ],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "print(condic.keys())\n",
    "dropnaset = ['FIQ', 'volume', 'Gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "573\n"
     ]
    }
   ],
   "source": [
    "hyp1 = ['bvol', 'fiq>0','normDev', softw] # ,'ants','abide']\n",
    "hyp1_df = apply_cond(hie, condic, hyp1, dropnaset=dropnaset, columns={'volume':'brainvol'})\n",
    "print(len(hyp1_df))\n",
    "\n",
    "hyp1_fsl = ['fiq>0','normDev', 'fsl']\n",
    "fsl_gm = hyp1_fsl + ['gmfsl'] #\n",
    "fsl_wm = hyp1_fsl + ['wmfsl'] #\n",
    "fsl_csf = hyp1_fsl + ['csffsl'] #\n",
    "\n",
    "fsl_gm_df = apply_cond(hie, condic, fsl_gm, dropnaset=dropnaset, columns={'volume':'fsl_gm'})\n",
    "fsl_wm_df = apply_cond(hie, condic, fsl_wm, dropnaset=dropnaset, columns={'volume':'fsl_wm'})\n",
    "fsl_csf_df = apply_cond(hie, condic, fsl_csf, dropnaset=dropnaset, columns={'volume':'fsl_csf'})\n",
    "\n",
    "fsl_total = pd.merge(left=fsl_gm_df, right=fsl_wm_df[['ID','fsl_wm']], left_on='ID', right_on='ID')\n",
    "fsl_total = pd.merge(left=fsl_total, right=fsl_csf_df[['ID','fsl_csf']], left_on='ID', right_on='ID')\n",
    "fsl_total['brainvol'] = fsl_total['fsl_csf'] + fsl_total['fsl_wm'] + fsl_total['fsl_gm']\n",
    "print(len(fsl_total))\n",
    "if softw == 'fsl':\n",
    "    tmp = fsl_total\n",
    "    hyp1 = hyp1_fsl\n",
    "else:\n",
    "    tmp = hyp1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Structure =  brainvol\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    FIQ   R-squared:                       0.147\n",
      "Model:                            OLS   Adj. R-squared:                  0.104\n",
      "Method:                 Least Squares   F-statistic:                     3.434\n",
      "Date:                Fri, 20 Dec 2019   Prob (F-statistic):           4.18e-07\n",
      "Time:                        12:30:28   Log-Likelihood:                -1800.5\n",
      "No. Observations:                 461   AIC:                             3647.\n",
      "Df Residuals:                     438   BIC:                             3742.\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                        86.2151     11.037      7.811      0.000      64.522     107.908\n",
      "study[T.ABIDE CMU_b Site]        15.6089     15.109      1.033      0.302     -14.087      45.305\n",
      "study[T.ABIDE KKI Site]          14.7060     15.106      0.974      0.331     -14.984      44.396\n",
      "study[T.ABIDE Leuven_1 Site]      0.2214     15.107      0.015      0.988     -29.471      29.914\n",
      "study[T.ABIDE MaxMun_c Site]      8.5004     15.242      0.558      0.577     -21.457      38.457\n",
      "study[T.ABIDE NYU Site]           3.2458      8.808      0.368      0.713     -14.066      20.557\n",
      "study[T.ABIDE OHSU Site]          5.7211      9.286      0.616      0.538     -12.529      23.971\n",
      "study[T.ABIDE Olin Site]          5.0217      9.251      0.543      0.588     -13.161      23.204\n",
      "study[T.ABIDE Pitt Site]         -1.2876      9.076     -0.142      0.887     -19.125      16.550\n",
      "study[T.ABIDE SDSU Site]         -1.7926      9.148     -0.196      0.845     -19.773      16.187\n",
      "study[T.ABIDE Stanford Site]      6.4696      9.190      0.704      0.482     -11.592      24.531\n",
      "study[T.ABIDE Trinity Site]      -2.0922      9.120     -0.229      0.819     -20.016      15.831\n",
      "study[T.ABIDE UCLA_1 Site]       -4.1032      8.992     -0.456      0.648     -21.775      13.569\n",
      "study[T.ABIDE UCLA_2 Site]        1.6163      9.368      0.173      0.863     -16.796      20.029\n",
      "study[T.ABIDE UM_1 Site]         -2.8822      8.888     -0.324      0.746     -20.350      14.586\n",
      "study[T.ABIDE UM_2 Site]          0.2753      9.136      0.030      0.976     -17.680      18.230\n",
      "study[T.ABIDE Yale Site]         -4.1197      9.028     -0.456      0.648     -21.864      13.625\n",
      "study[T.ADHD200 - NYU]            3.5743      9.424      0.379      0.705     -14.948      22.096\n",
      "study[T.ADHD200 - Peking_1]       7.2431      9.052      0.800      0.424     -10.548      25.034\n",
      "study[T.ADHD200 - Peking_2]      11.3232      9.003      1.258      0.209      -6.371      29.017\n",
      "study[T.ADHD200 - Peking_3]      -0.1304      9.489     -0.014      0.989     -18.781      18.520\n",
      "study[T.ADHD200 - Pittsburgh]    -0.0670     10.319     -0.006      0.995     -20.349      20.215\n",
      "Q('brainvol')                  1.628e-05   4.73e-06      3.442      0.001    6.99e-06    2.56e-05\n",
      "==============================================================================\n",
      "Omnibus:                        5.317   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.070   Jarque-Bera (JB):                5.424\n",
      "Skew:                          -0.190   Prob(JB):                       0.0664\n",
      "Kurtosis:                       3.372   Cond. No.                     1.06e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.06e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(\" Structure = \", 'brainvol')\n",
    "#assert ube2h[tmp.iloc[0]['structure']] == roi\n",
    "\n",
    "iq = 'FIQ'\n",
    "\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "md = smf.ols(iq + \" ~ Q('brainvol') + study \", data=tmp) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "varname = \"Q('brainvol')\"\n",
    "hyp_name = 'PIET-1'\n",
    "resdic.update(md2dic(varname, hyp_name, hyp1, mdf=mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PIET-1': {'P>|t|': ' 0.001',\n",
       "  't': '    3.442',\n",
       "  'rsquared_adj': '0.104',\n",
       "  'nobs': '461',\n",
       "  'conditions': ['bvol', 'fiq>0', 'normDev', 'ants']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df and conditions for left striatum, all age all gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mac = ['fiq>0','normDev', softw,'left'] # ,'age<20']\n",
    "mac_caud = cond_mac + ['caudate'] #\n",
    "mac_put = cond_mac + ['putamen'] #\n",
    "mac_tiv = cond_mac + ['fiq>0','normDev',softw,'TIV'] #\n",
    "\n",
    "left_caud = apply_cond(hie, condic, mac_caud, dropnaset=dropnaset, columns={'volume':'caudate'})\n",
    "left_put = apply_cond(hie, condic, mac_put, dropnaset=dropnaset, columns={'volume':'putamen'})\n",
    "\n",
    "left_stria = pd.merge(left=left_caud, right=left_put[['ID','putamen']], left_on='ID', right_on='ID')\n",
    "left_stria['striatum'] = left_stria['caudate'] + left_stria['putamen']\n",
    "left_stria_condic = define_conditions(left_stria, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "print(len(left_stria))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-1: Left striatum volume (caudate + putamen) will positively correlate with IQ in the total (male + female) child (age < 20) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac1_cond = ['age<20']\n",
    "mac1 = apply_cond(left_stria, left_stria_condic, mac1_cond)\n",
    "print(len(mac1))\n",
    "\n",
    "\n",
    "iq = 'FIQ'\n",
    "\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "# md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('striatum') + study \", data=mac1) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname = \"Q('striatum')\"\n",
    "hyp_name = 'MAC-1'\n",
    "resdic.update(md2dic(varname, hyp_name, cond_mac+mac1_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-2: Left striatum volume (caudate + putamen) will positively correlate with IQ in the male children group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac2_cond = ['age<20','male']\n",
    "mac2 = apply_cond(left_stria, left_stria_condic, mac2_cond)\n",
    "print(len(mac2))\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "# md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('striatum') + study \", data=mac2) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname = \"Q('striatum')\"\n",
    "hyp_name = 'MAC-2'\n",
    "resdic.update(md2dic(varname, hyp_name, cond_mac+mac2_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC-3: Left striatum volume (caudate + putamen) will not correlate with IQ in the female children group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac3_cond = ['age<20','female']\n",
    "mac3 = apply_cond(left_stria, left_stria_condic, mac3_cond)\n",
    "print(len(mac3))\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "# md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('striatum') + study \", data=mac3) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('striatum')\",'MAC-3'\n",
    "resdic.update(md2dic(varname, hyp_name, cond_mac+mac3_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute cc and tbv  for GANJ, no age or gender condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condic = define_conditions(hie, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n",
    "condic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softw = 'fs'\n",
    "hypGanj = ['fiq>0','normDev', softw] # ,'age<20'\n",
    "hyp_ccant = hypGanj + ['ccant'] #\n",
    "hyp_cccen = hypGanj + ['cccen'] #\n",
    "hyp_ccpos = hypGanj + ['ccpos'] #\n",
    "\n",
    "ccant = apply_cond(hie, condic, hyp_ccant, dropnaset=dropnaset, columns={'volume':'ccant'})\n",
    "cccen = apply_cond(hie, condic, hyp_cccen, dropnaset=dropnaset, columns={'volume':'cccen'})\n",
    "ccpos = apply_cond(hie, condic, hyp_ccpos, dropnaset=dropnaset, columns={'volume':'ccpos'})\n",
    "\n",
    "cc = pd.merge(left=ccant, right=cccen[['ID','cccen']], left_on='ID', right_on='ID')\n",
    "cc = pd.merge(left=cc, right=ccpos[['ID','ccpos']], left_on='ID', right_on='ID')\n",
    "\n",
    "cc['cc'] = cc['ccant']+cc['cccen']+cc['ccpos']\n",
    "len(cc), len(ccant), len(cccen), len(ccpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_gm = hypGanj + ['gm'] #\n",
    "gm = apply_cond(hie, condic, hyp_gm, dropnaset=dropnaset, columns={'volume':'gm'})\n",
    "#print(gm[['ID','gm','laterality']].head(2),len(gm))\n",
    "\n",
    "hyp_wm = hypGanj + ['wm','latNan'] #\n",
    "wm = apply_cond(hie, condic, hyp_wm, dropnaset=dropnaset, columns={'volume':'wm'})\n",
    "#print(wm[['ID','wm','laterality']].head(2),len(wm))\n",
    "\n",
    "hyp_csf = hypGanj + ['csf'] #\n",
    "csf = apply_cond(hie, condic, hyp_csf, dropnaset=dropnaset, columns={'volume':'csf'})\n",
    "#print(csf[['ID','csf','laterality']].head(2),len(csf))\n",
    "tbv = pd.merge(left=gm, right=wm[['ID','wm']], left_on='ID', right_on='ID')\n",
    "tbv = pd.merge(left=tbv, right=csf[['ID','csf']], left_on='ID', right_on='ID')\n",
    "tbv['tbv'] = tbv['wm'] + tbv['gm'] +  tbv['csf']\n",
    "print(len(gm), len(wm), len(csf), len(tbv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_tbv = pd.merge(left=tbv, right=cc[['ID','cc']], left_on='ID', right_on='ID')\n",
    "condic_cc_tbv = define_conditions(cc_tbv, tooldic=tooldic, normalDev=normalDev, adhd=adhd, h2ube=h2ube)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-1: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganj1_cond = ['age<20'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "ganj1 = apply_cond(cc_tbv, condic_cc_tbv, ganj1_cond)\n",
    "print(list(ganj1),len(ganj1))\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj1) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-1'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj1_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-2: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the young (age < 12) group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganj2_cond = ['age<12'] #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "ganj2 = apply_cond(cc_tbv, condic_cc_tbv, ganj2_cond)\n",
    "print(list(ganj2),len(ganj2));\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj2) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-2'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj2_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-3: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the adolescent (age > 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganj3_cond = ['age>=12'] #\n",
    "ganj3 = apply_cond(cc_tbv, condic_cc_tbv, ganj3_cond)\n",
    "print(len(ganj3))\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj3) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-3'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj3_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-4:. Total Corpus Callosum midsagittal area, after correcting for total brain volume, will negatively correlate with IQ in the male (age < 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganj4_cond = ['age<12','male'] #+ hypGanj #'fiq>0','normDev','fs','age<=20','ccant'] #\n",
    "ganj4 = apply_cond(cc_tbv,  condic_cc_tbv, ganj4_cond)\n",
    "print(list(ganj4),len(ganj4),'\\n')\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj4) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-4'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj4_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANJ-5: Total Corpus Callosum midsagittal area, after correcting for total brain volume, will not significantly correlate with IQ in the female (age < 12) group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganj5_cond = ['age<12','female'] #,'fiq>0','normDev','fs','age<=20'\n",
    "ganj5 = apply_cond(cc_tbv,  condic_cc_tbv, ganj5_cond)\n",
    "print(list(ganj5),len(ganj5),'\\n')\n",
    "\n",
    "iq = 'FIQ'\n",
    "# md = smf.ols(iq + \" ~ Q('volume') + Gender + Age + study \", data=tmp) #  \n",
    "#md = smf.ols(iq + \" ~ Q('striatum') + study + TIV \", data=stria) #  \n",
    "md = smf.ols(iq + \" ~ Q('cc') + study + tbv \", data=ganj5) #  \n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "\n",
    "\n",
    "varname, hyp_name = \"Q('cc')\",'GANJ-5'\n",
    "resdic.update(md2dic(varname, hyp_name, hypGanj+ganj5_cond, mdf=mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hyp2 = ['fiq>0','normDev','fs','age<20']\n",
    "hyp2_caud = hyp2 + ['caudate'] # ,'abide']\n",
    "hyp2_put = hyp2 + ['putamen'] # ,'abide']\n",
    "hyp2_tiv = hyp2 + ['TIV'] # ,'abide']\n",
    "tmp_caud = apply_cond(hie, condic, hyp2_caud, dropnaset=dropnaset)\n",
    "caud = split_merge_df(tmp_caud, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+',colrename='caudate')\n",
    "tmp_put = apply_cond(hie, condic, hyp2_put, dropnaset=dropnaset)\n",
    "put = split_merge_df(tmp_put, indx='ID', spliton='laterality', levels=['Left','Right'], \n",
    "                       keep_col='volume', op='+',colrename='putamen')\n",
    "tmp_tiv = apply_cond(hie, condic, hyp2_tiv, dropnaset=dropnaset)\n",
    "print(len(caud), len(put), len(tmp_tiv))\n",
    "\n",
    "stria = pd.merge(left=caud, right=put[['ID','putamen']], left_on='ID', right_on='ID')\n",
    "stria['striatum'] = stria['caudate']+stria['putamen']\n",
    "stria = pd.merge(left=stria, right=tmp_tiv[['ID','volume']], left_on='ID', right_on='ID')\n",
    "stria.rename(columns={'volume':'TIV'},inplace=True)\n",
    "print(list(stria),len(stria))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
